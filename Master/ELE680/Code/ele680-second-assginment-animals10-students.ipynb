{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## ANIMAL CLASSIFICATION - ASSIGNMENT 2","metadata":{"_uuid":"9a3f4b28-adab-44b4-a1b8-67284a87c7a1","_cell_guid":"999855c8-48c5-4fc0-8412-18f1a4e7be56","trusted":true}},{"cell_type":"markdown","source":"In previous assignment, we solved a binary classification problem for tabular data by using a simple Multilayer Perceptron (MLP). The aim was to familiarise yourself with some basic commands to implement a Deep Learning (DL) model and to emphasise the importance of knowing your data. We are now ready to move on to the next level!\n\nHere, we will work with Convolutional Neural Networks (CNNs). As you have learn during this course, there are some families of DL architectures that are more suitable for a particular task depending on the problem to be solved, the data you are working with, etc. Introduced by Yann LeCun in 1989, CNNs have been the most used architectures when it comes to Computer Vision applications like Image Classification (until the Transformers came along, but that is a different topic...). \n\nIn this assignment, we aim to implement a CNN in order to *classify images of 10 different animals*. One could wonder, is classifying animals that useful? And the answer is.. probably not! But think about the big picture: you could learn to classify (and diagnose) a specific disease based on medical images, for instance. We will split this assignment in 4 sections:\n\n* EDA and Data Preprocessing\n* CNN Implementation\n* Data Augmentation\n* Transfer Learning\n\nAs we did before, the first step is to understand our data. As we are working with images, we will focus on gaining some knowledge about the distribution of our data and how to deal with it, as well as displaying some image examples. Then, we will prepare the data to be fed in our CNN. Then, we will implement a basic Convolutional Neural Network to train our multiclass classifier since we deal with images as our input. We will also apply some data augmentation to see the influence of this technique during training. Finally, we will make use of a pre-existing model from the Keras library - namely VGG16, one of the very first \"well-known\" convolution-based architectures. We will experiment with what is called *Transfer learning*, a really common practice in the DL world in which we simply make use of pre-existing weight values (features) for our architecture. Those pre-existing values were obtained by training the architecture on a large corpus of images (ImageNet) and can be used to accelerate the training process.\n\nLet's start!\n\n**NOTE**: Our model deployment will be carried out with **TensorFlow**. In Kaggle, we can make use of some free GPUs available to speed up the training process. To run notebooks with GPU (we will really need it in this assignment), select the GPU P100 option in the accelerator setting. You will find this option by clicking in the three vertical dots in the top-right corner of the Notebook.\n\n**NOTE**: In Keras, there are two ways of defining a model: Sequential (as previous assignment) and Functional API. In this assignment, we are going to use the Keras Functional API. To get familiar with this flexible way to create models, please take a quick look to the Introduction section in [this tutorial](https://www.tensorflow.org/guide/keras/functional#introduction).\n\n**NOTE**: Througout the different tasks in this assignment, you will find some questions marked as **Q**. These questions should be answered at the end of the Notebook (there is a Markdown cell prepared for this purpose).","metadata":{"_uuid":"980a35c7-7b8d-4a7e-b676-1818386e3cff","_cell_guid":"23ed95ca-2d11-4ac1-91d6-618a2cfd8208","trusted":true}},{"cell_type":"markdown","source":"### Installing Libraries\n\nTo enable the installation of libraries in Kaggle, go to **Notebook options** and activate *Internet* option. Then, install the following libraries:","metadata":{}},{"cell_type":"code","source":"!pip install keras==2.12.0\n!pip install matplotlib==3.6.3\n!pip install numpy==1.23.5\n!pip install pandas==1.5.3\n!pip install scikit_learn==1.2.2\n!pip install seaborn==0.12.2\n!pip install tensorflow==2.12.0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### EDA and Data Preprocessing\n\nThe first thing you'll need to do, is to load the dataset from Kaggle. To do that, we need to add the dataset to our notebook. This can be done by clicking in *Add data* in the top-right corner of the notebook and searching for **Animals-10** (Corrado Alessio). Once the dataset has been added (it should appear in our notebook's input, again in the top-right corner), we can start. If you want to learn more about the information contained in this dataset, check https://www.kaggle.com/datasets/alessiocorrado99/animals10.","metadata":{"_uuid":"60d02407-404d-42dd-af85-faa2c1c57a91","_cell_guid":"31858204-1eaa-4044-b533-a2ef152e915e","trusted":true}},{"cell_type":"code","source":"# Imports\nimport pandas as pd\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport random\nimport os\nfrom pathlib import PurePosixPath as PPP\n\nfrom sklearn.preprocessing import LabelEncoder\nimport seaborn as sns\n\nfrom tensorflow.keras import mixed_precision\nmixed_precision.set_global_policy('mixed_float16')","metadata":{"_uuid":"c79d2439-0db9-410d-89d2-f87dd1f68e47","_cell_guid":"2b537175-d145-44f9-9946-744a7011e88d","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Task 1**\n\nAs you can see, our data is stored by classes. Our first task is to read the dataset and create the independent variable containing our ground truth (labels) for the classification task. Once we have created our array containing the values of the ground truth, we can store them in a dataframe (we are already familiar with Pandas). Store the name of the file and its associated category in a dataframe.","metadata":{"_uuid":"6e2f2eaa-4480-42cb-9653-430f4a3af915","_cell_guid":"506f7559-3b18-4dc2-98d9-455c12991dde","trusted":true}},{"cell_type":"code","source":"# Read all files\nraw_path = \"../input/animals10/raw-img\"\nfilename_data = []\nfor (dirpath, dirnames, filenames) in os.walk(raw_path):\n    if '.py' in filenames: continue # Skip python file included in the main folder\n    filename_data  += [str(PPP(dirpath).joinpath(file)) for file in filenames]\n    \n# Ground truth\ncategories = []\n\n# Loop over the filenames and use \"split\" to get the category name.\nfor file in filename_data:\n    categories.append() # Type your solution here\n        \n# Create a dataframe containing the names of the files and the categories. Use 'filename' and 'labels' as column names.\ndf =  # Type your solution here.\n\n# Show random samples\ndf.sample(n=9, random_state=6)","metadata":{"_uuid":"46873c49-1669-47d7-8bc7-16665a27251e","_cell_guid":"d54766ee-e239-4b1d-b647-e89f844d40c7","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As you can see, the original dataset is in Italian. Let's make use of the dictionary contained in *translate.py* to translate the labels. It will be much easier to work in English :)","metadata":{"_uuid":"c94dd976-84df-433f-8c16-91e284c3aa37","_cell_guid":"172b2c6e-b59b-446a-a420-cfb12fa74ebe","trusted":true}},{"cell_type":"code","source":"# Dictionary\nlabel_mapping = {\"cane\": \"dog\", \"cavallo\": \"horse\", \"elefante\": \"elephant\", \"farfalla\": \"butterfly\", \"gallina\": \"chicken\", \n                 \"gatto\": \"cat\", \"mucca\": \"cow\", \"pecora\": \"sheep\", \"scoiattolo\": \"squirrel\",\"ragno\": \"spyder\"}\n\n# Use .map() function to translate the 'labels' column\ndf['labels'] =  # Type your solution here.\n\n# Show same random samples\ndf.sample(n=9, random_state=6)","metadata":{"_uuid":"ce0b2b5b-792f-47aa-b1b0-ed45dfbcdcf5","_cell_guid":"a886f440-b45a-4242-a735-3a515d84c523","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Task 2**\n\nUse the \"labels\" of the dataframe and value_counts() to plot a bar plot showing the class distribution of the data.\n\n**Q1**: As you can see, the data is not equally distributed. An alternative could be to resampling our dataset (oversampling or undersampling) until the dataset is balanced. In our case, we will not consider this but, can you think of ways to solved the imbalanced data issue? Do you know any particular application where data is usually highly unbalanced?","metadata":{"_uuid":"6ad9f480-3564-453e-97b2-7a59b9a42b56","_cell_guid":"1a3801f0-b568-4b81-be72-8af65844cd5e","trusted":true}},{"cell_type":"code","source":"# Get the value counts for each label\nlabel_counts =  # Type your solution here.\n\n# Create the figure and axes\nfig, axes = plt.subplots(nrows=1, ncols=1, figsize=(20, 6))\n\n# Plot the bar chart using label_counts index and values\nsns.barplot(x=, y=, alpha=0.8, palette='pastel', ax=axes) # Type your solution here.\naxes.set_title('Distribution of Labels in Image Dataset', fontsize=16)\naxes.set_xlabel('Label', fontsize=14)\naxes.set_ylabel('Count', fontsize=14)\naxes.set_xticklabels(label_counts.index, rotation=45)\n\n# Add a super-title to the figure\nfig.suptitle('Image Dataset Label Distribution', fontsize=20)\n\n# Adjust the spacing between the plots and the title\nfig.subplots_adjust(top=0.85)\n\n# Display the plot\nplt.show()\n\nprint(\"Number of images per category : \")\nprint(label_counts)","metadata":{"_uuid":"98f0ee23-3d7c-4873-9375-d03a7bb3d1ce","_cell_guid":"862df139-5e66-4121-a880-4d670901c7cd","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Task 3** \n\nOnce we have loaded the dataset, we will proceed to show some examples. Plot the same random samples we have been showing before to get an idea of how our data looks like.","metadata":{"_uuid":"725a1b8a-9f73-4898-a731-cde243b83a9e","_cell_guid":"b1fc4cc0-459f-4da3-83c0-0c0a7ef4cd6a","trusted":true}},{"cell_type":"code","source":"# Extract 9 random samples using random_state=6. Remember to reset indexes with reset_inex()\nsample_df =  # Type your solution here.\n\nplt.figure(figsize=(12, 12))\nfor index, row in sample_df.iterrows():\n    filename =  # Type your solution here.\n    category =  # Type your solution here.\n    img = load_img(filename, target_size=(256, 256))\n    plt.subplot(3, 3, index+1)\n    plt.imshow(img)\n    plt.xlabel(category)\nplt.tight_layout()\nplt.show()","metadata":{"_uuid":"f24564e1-bb41-49d9-8813-292c188c722a","_cell_guid":"962d779d-3bde-4131-a8ea-fef6170c3bb3","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Task 4**\n\nSimilar to Assignment 1, we need to convert the non-numerical variables (categorical) to numerical. In this case, we will make use of the LabelEncoder() function to encoder our labels and store them in a new \"encoded_labels\" column.","metadata":{"_uuid":"1940ad21-c8ac-4a79-aaaa-6d7f35da77e3","_cell_guid":"52fa47fb-3832-409f-8adc-e67e8de0e776","trusted":true}},{"cell_type":"code","source":"# Create a encoder object\nlb =  # Type your solution here.\n\n# Use fit_transform to fit the data and encode it\ndf['encoded_labels'] =  # Type your solution here.\n\n# Show same random samples\ndf.sample(n=9, random_state=6)","metadata":{"_uuid":"5e32824b-2a81-4baa-bb28-cdf58b75d212","_cell_guid":"981796bf-c9c4-4c80-aed3-d04d84fe43a4","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Task 5** \n\nTime to prepare the data for the architecture! Remember that we already have the dataframe containing the names and class of each image. We will split in training, validation and test. Make use of the dataframe to obtain a train set with 70% of the data. The remaining data will be equally divided into validation and test set. Use train_test_split() funtion including *suffle=True* , *random_state=0* and *stratify* arguments when splitting. More info here https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html","metadata":{"_uuid":"e21bac53-05a0-493c-bcdc-5992193781e2","_cell_guid":"eb6f9661-809a-49ab-b4c7-869d2e1f695c","trusted":true}},{"cell_type":"code","source":"# Split dataset\ntrain_df, Temp_df = train_test_split(, train_size=, shuffle=True, \n                                     random_state=0, stratify=df['labels'])  # Type your solution here\nvalid_df, test_df = train_test_split(, train_size=, shuffle=True, \n                                     random_state=0, stratify=Temp_df['labels']) # Type your solution here\n\ntrain_df = train_df.reset_index(drop=True)\nvalid_df = valid_df.reset_index(drop=True)\ntest_df = test_df.reset_index(drop=True)\n\nprint(\"Shape of the training set:\", train_df.shape)\nprint(\"Shape of the validation set:\", valid_df.shape)\nprint(\"Shape of the testing set:\", test_df.shape)","metadata":{"_uuid":"68073f40-7648-419e-9cfe-f6c4a58fb99a","_cell_guid":"dc595272-c2b1-4423-98b3-202e2089e1cc","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Task 6**\n\nFor feeding the data into our model, we will make use of the ImageDataGenerator() class. Here, we can use some of the predefined transforming/preprocessing methods included. Use flow_from_dataframe() with an ImageDataGenerator that will only apply a rescale to the images (1./255) with a batch size of 64. We will also resize our images to a (224,224). Later, we will use such generator with more operations to perform data augmentation at training time but for now, let's keep it simple. The reescaling operation simply makes sure that all the pixel values of the images fall in between a defined range [0-1], which helps the training of the network.","metadata":{"_uuid":"f2a49f86-4ba7-41c1-a721-61610cd83418","_cell_guid":"35f75e47-bfb0-485f-939f-912c31a5f334","trusted":true}},{"cell_type":"code","source":"# Convert labels to string\ntrain_df[\"encoded_labels\"] = train_df['encoded_labels'].astype(str)\nvalid_df[\"encoded_labels\"] = valid_df['encoded_labels'].astype(str)\n\ntrain_datagen = ImageDataGenerator(\n    rescale=, # Type your solution here\n)\n\n# Include the column name for x and y\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe=train_df, \n    x_col=, # Type your solution here\n    y_col=, # Type your solution here\n    class_mode='categorical',\n    target_size=, # Type your solution here\n    batch_size= 64\n)\n\nvalidation_datagen = ImageDataGenerator(\n    rescale=, # Type your solution here\n)\n\n# Include the column name for x and y\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    dataframe=valid_df, \n    x_col=, # Type your solution here\n    y_col=, # Type your solution here\n    class_mode='categorical',\n    target_size=, # Type your solution here\n    batch_size= 64\n)","metadata":{"_uuid":"d2e68cde-0285-44da-a6a6-3fc449e0003f","_cell_guid":"2a68b51f-c1c6-4cf3-9f3b-1f36406719c0","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### CNN Implementation\n\nTime to implement our classifier! We will first create our \"homemade\" model. Later on, we will make use of one of the well-known architectures instead. Unlike assignment 1, dealing with images is computacionally heavy so the trainining process is slower. Please, make sure you followed the steps mentioned in the introduction of this Notebook to use of the Kaggle's GPUs. We will run just a few epochs (around 10 min), but take into account that, in real applications, training can last for thousands of epochs depending on the task.","metadata":{"_uuid":"847ce44d-a616-4c47-baf5-2790bef1abee","_cell_guid":"91c08417-03ac-4a09-a8aa-cb99eb386a4a","trusted":true}},{"cell_type":"markdown","source":"**Task 7** \n\nCreate a 4-layer CNN with 32, 64, 128 and 128 units respectively with a (3,3) kernel and Rectified Linear Unit as activation function. Add a MaxPooling2D after each CNN layer with pool size (2,2) to reduce the spatial dimension.\n\n**Q2**: Two of the important ideas that CNNs leverages are *sparse interaction* (or locally connected layers) and *parameter sharing*. Explain briefly both of them.","metadata":{"_uuid":"a85830b4-6561-4f2a-976f-bae94950041d","_cell_guid":"f56bf8ff-a5c4-4507-a9a4-5ec06eb6644e","trusted":true}},{"cell_type":"code","source":"from tensorflow.keras import layers\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, GlobalMaxPooling2D, Input\nfrom tensorflow.keras import applications\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.models import Model\n\n# Which input shape? Remember to include the number of channels...\ninput_shape = () # Type your solution here.\n\n# How many classes?\nnum_classes =  # Type your solution here.\n\ndef create_basic_model(input_shape):\n    \n    # Use the Input layer with the right input shape\n    inputs = Input(shape=) # Type your solution here\n    \n    # Basic CNN model. Type your solution here. \n    x = \n    x = \n    x = \n    x = \n    x = \n    x = \n    x = \n    x = \n    \n    # Add a Dropout with prob. 0.5\n    x =  # Type your solution here\n    \n    # Flatten the output layer to 1 dimension.\n    x =  # Type your solution here\n    \n    # Add a fully connected layer with 512 hidden units and ReLU activation.\n    x =  # Type your solution here\n    \n    # Add the final layer (Dense) with the right activation.\n    output =  # Type your solution here\n    \n    # Create a Model() with the right input and output\n    model =  # Type your solution here\n    \n    # Show a summary of the model to make sure there are no disconnected elements.\n    # Type your solution here\n    \n    return model\n\nmodel = create_basic_model(input_shape)","metadata":{"_uuid":"63dee02a-bacf-480a-ba55-2b6b114c3531","_cell_guid":"8f9d0d4d-245f-4855-85c4-ed97157aba78","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Task 8**\n\nLet's train the model! Use fit() with the generators that we have already defined (validation and training). Run it for 10 epochs with Adam optimizer and learning rate of 0.001. Use the total amount of samples (obtained from the dataframe) to define the number of steps for both training (steps_per_epoch) and validation (validation_steps) (total_samples//batch_size). Plot the curves (loss and accuracy).","metadata":{"_uuid":"cadde954-92f2-40da-aaa4-c6acd70a8238","_cell_guid":"a0fb1c24-666d-4738-a571-ff6986ac398c","trusted":true}},{"cell_type":"code","source":"#  Use compile with the right loss, optimizer and metrics\nmodel.compile(loss=, # Type your solution here.\n              optimizer=, # Type your solution here.\n              metrics=) # Type your solution here.\n\n# Training\nhistory = model.fit(\n    x=, # Type your solution here (use the training generator),\n    epochs=, # Type your solution here\n    validation_data=, # type your solution here (use validation generator),\n    validation_steps=, # Type your solution here,\n    steps_per_epoch=, # Type your solution here\n)","metadata":{"_uuid":"a64e0f0e-a78a-467b-8718-ccccf75f5508","_cell_guid":"4047db1b-bd3c-4126-886b-574a5370b843","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the accuracy curves\nf,ax=plt.subplots(1,2,figsize=(18,8))\n\nax[0].plot() # Type your solution\nax[0].plot() # Type your solution\nax[0].set_title('model accuracy')\nax[0].set_ylabel('accuracy')\nax[0].set_xlabel('epoch')\nax[0].legend(['train', 'val'], loc='upper left')\n\nax[1].plot() # Type your solution\nax[1].plot() # Type your solution\nax[1].set_title('model loss')\nax[1].set_ylabel('loss')\nax[1].set_xlabel('epoch')\nax[1].legend(['train', 'val'], loc='upper left')","metadata":{"_uuid":"08ffe318-7f97-467f-8225-c3bf84e2eb58","_cell_guid":"466e7cf0-8032-4a3f-8d8a-ab8e8e040fdb","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Augmentation\n\nAs you've seen, training a convolutional neural network can be quite a long process, even when resources such as GPU are available. Moreover, the progress can be quite slow in terms of improved performance over time - our results in the previous run were not particularly impressive! As we see in the plots, the validation dataset seems to flatten over time in performance, whereas the training is almost perfect. This is an indicator of overfitting in our model. Nevertheless, there are some techniques than can help with this situation. Data augmentation refers to applying transformations during training such that the network learns that a cat is still a cat even if it, for instance, rotated!. Augmentation can be particularly useful when dealing with small datasets, as it is a way to \"have more information\" without the burden of labeling more data.\n\n**SPOILER**: The training process is going to be even slower than before...","metadata":{"_uuid":"7faffdae-40ac-4951-a394-506157edad66","_cell_guid":"456704a7-d8ef-48f7-a6b1-a08f35a9ee02","trusted":true}},{"cell_type":"markdown","source":"**Task 9**\n\nRe-define our data generators but this time apply rotation (30 degrees), horizontal flip, width and height shift (0.1) and zooming (0.2). Be careful, since we want to apply the augmentations to the training set ONLY. Display the same sample generated by the new generators after applying the different transformations.","metadata":{"_uuid":"f747b774-417f-4176-917b-5730a73ec779","_cell_guid":"b3f828b7-138e-4a0f-bc6e-353ef85afa58","trusted":true}},{"cell_type":"code","source":"# Train generator with Data Augmentation\ntrain_datagen_aug = ImageDataGenerator(\n        rescale=1./255,\n        rotation_range=, # Type your solution here\n        width_shift_range=, # Type your solution here\n        height_shift_range=, # Type your solution here\n        zoom_range=, # Type your solution here\n        horizontal_flip=, # Type your solution here\n        fill_mode='nearest'\n)\n\ntrain_generator_aug = train_datagen_aug.flow_from_dataframe(\n    dataframe=train_df, \n    x_col=, # Type your solution here\n    y_col=, # Type your solution here\n    class_mode=, # Type your solution here\n    target_size=(224, 224),\n    batch_size= 64\n)","metadata":{"_uuid":"bd608d37-6e98-4589-94e5-68a02dd2f5cd","_cell_guid":"c4ce8813-54c8-4b4a-b1d4-c4cb5a007e61","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extact only one sample from the training et\nsample_df_aug =  # Type your solution here\n\n# Create an example_generator using the train_datagen_aug\nexample_generator = train_datagen_aug.flow_from_dataframe(\n    dataframe=sample_df_aug,  # Type your solution here\n    x_col=, # Type your solution here\n    y_col=, # Type your solution here\n    class_mode=, # Type your solution here\n) # Type your solution here\n\nplt.figure(figsize=(12, 12))\n\nfor i in range(0, 9):\n    plt.subplot(3, 3, i+1)\n    for X_batch, Y_batch in example_generator:\n        image = X_batch[0]\n        plt.imshow(image)\n        break\nplt.tight_layout()\nplt.show()","metadata":{"_uuid":"6656c59d-1e53-4bed-97db-9b2df1318107","_cell_guid":"bac10c06-86f2-4a3c-9576-d68abc9349ed","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Task 10** \n\nLet's train a new model with the new generators for 10 epochs. Compile the model and train it with the same configuration previously used. Plot the new validation/train curves.","metadata":{"_uuid":"86bc6c4f-77b9-4db7-847f-215d84463cd2","_cell_guid":"4f488b4b-480b-4ed7-8adb-b55b20d6c472","trusted":true}},{"cell_type":"code","source":"# Create a new model by calling to create_basic_model().\nmodel_aug =  # Type your solution here.\n\n# Use compile with the right loss, optimizer and metrics\nmodel_aug.compile(loss=, # Type your solution here.\n              optimizer=, # Type your solution here.\n              metrics=) # Type your solution here.\n\n# Training\nhistory_aug = model_aug.fit(\n    x=, # Type your solution here (use the training generator),\n    epochs=, # Type your solution here\n    validation_data=, # type your solution here (use validation generator),\n    validation_steps=, # Type your solution here,\n    steps_per_epoch=, # Type your solution here\n)","metadata":{"_uuid":"c464fe99-4d03-47a2-95b8-b8c8fcfb6419","_cell_guid":"52f384a3-b517-4c2d-adde-3b9298fc7726","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the accuracy curves\nf,ax=plt.subplots(1,2,figsize=(18,8))\n\nax[0].plot() # Type your solution\nax[0].plot() # Type your solution\nax[0].set_title('model accuracy')\nax[0].set_ylabel('accuracy')\nax[0].set_xlabel('epoch')\nax[0].legend(['train', 'val'], loc='upper left')\n\nax[1].plot() # Type your solution\nax[1].plot() # Type your solution\nax[1].set_title('model loss')\nax[1].set_ylabel('loss')\nax[1].set_xlabel('epoch')\nax[1].legend(['train', 'val'], loc='upper left')","metadata":{"_uuid":"810b4c6f-63c7-4781-8fea-7603a44b58e3","_cell_guid":"78c8163f-0d18-4f1a-b3f0-30dcf9277fb2","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Transfer Learning\n\nAs you've verified, data augmentation may offer improvement over the basic convolutional setting. In this case, with the same amount of epochs, the validation performance is similar than the previous experiment, but there is still room for improving on the training set (and, hopefully, on the validation set as well). Although the more preprocessing steps we add to our generator the slower the training process is, this technique usually helps the model to generalize better. Let's try a different thing... Like it has been mentioned, transfer learning is a really common approach to DL problems. A lot of tasks/datasets benefit from using ImageNet pretrained weights. Let's try to use them and see the effect on our task! \n\n**NOTE**: In this experiment, we skip the use of data augmentation to train our model faster.","metadata":{"_uuid":"97cbfeaa-9d27-47e1-a136-00fd71cb5fe2","_cell_guid":"641ce7b2-12b7-4ace-961c-5420eecf753f","trusted":true}},{"cell_type":"markdown","source":"**Task 11** \n\nCreate a model that makes use of ImageNet pretraining weights. Make use of keras.applications VGG16. Don't include the classification head (top) of VGG16, we will add our own custom one instead. USe GlobalMaxPooling2D to flatten the output of VGG16 and then add a Dense layer with 512 hidden units and ReLU activation. Following, add a Dropout layer with 0.5 probability. Finally, add a Dense layer with the right number of units and activation function. Finally, we will freeze the whole architecture excet for the last layers (7 onwards). Feel free to experiment with the number of frozen layers to see the effect of fine-tuning different layers.","metadata":{"_uuid":"fc32311a-507a-45c1-9189-4ad9ea1c6c40","_cell_guid":"c7050f71-cf23-42ae-83df-c02b427ad7b3","trusted":true}},{"cell_type":"code","source":"from tensorflow.keras.applications import VGG16\n\n# Which input shape? Remember to include the number of channels...\ninput_shape = () # Type your solution here.\n\n# How many classes?\nnum_classes =  # Type your solution here.\n\n# Number of trainable layers\ntrain_layer =  # Type your solution here.\n\ndef create_ImageNet_model(input_shape, TRAINABLE_LAYERS):\n\n    vgg16 = VGG16(input_shape=, include_top=, weights=\"imagenet\") # Type your solution here\n\n    # Flatten the VGG16 output layer to 1 dimension with GlobalMaxPooling2D()\n    x = # Type your solution here\n    \n    # Add a fully connected layer with 512 hidden units and ReLU activation\n    x = # Type your solution here\n    \n    # Add a dropout rate of 0.5\n    x = # Type your solution here\n    \n    # Add a final layer to classify\n    output = # Type your solution here\n\n    # Create a Model() with the right input and output.\n    model = # Type your solution here\n    \n    # Loop over the layers that we want to set as trainable (True).\n    # Leave the rest of layers frozen (False)\n    for layer in model.layers[:-TRAINABLE_LAYERS]:\n        layer.trainable = \n    \n    for layer in model.layers[-TRAINABLE_LAYERS:]: # Type your solution here\n        layer.trainable =  # Type your solution here\n\n    # Print a summary of the model to make sure there are no disconnected elements.\n    # Type your solution here\n    \n    return model\n\n# Create model\nmodel_imgnet = create_ImageNet_model(input_shape, train_layer)","metadata":{"_uuid":"c20fde06-8f8b-41be-9261-b8307464c8db","_cell_guid":"2039e9f5-d138-4da9-95c7-35f84163b0cf","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Task 12** \n\nTransfer learning has not only benefits in terms of final performance but also in terms of training speed and convergence - it is the right moment to introduce an early stopping mechanism!. Such approach pre-defines a criteria to stop the training if certain conditions are met. For intstance, if the validation loss does not improve for 5 epochs -> training is stopped. Implement the early stopping callback and monitorize the validation loss. Stop the training if there is no improvement for more than 3 consecutive epochs. You should take into account that the point in which the training has been stopped is probably not the optimal one in terms of performance. That is why, usually, we make use of another callback in addition to early stopping. Create a model checkpoint callback. We will recover (load the weights) of the best epoch in terms of performance after the early stopping has been triggered. The checkpoint should focus on maximum model accuracy. Save the best weights only.","metadata":{"_uuid":"16bb950f-bfa0-4196-9105-2bf5347272f2","_cell_guid":"71913aad-668c-411d-b167-1a16880af943","trusted":true}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\n# Type your solution here (choose the right values)\nes = EarlyStopping(monitor=, mode=\"auto\", verbose=1, patience=)\n\n# Type your solution here\nmc = ModelCheckpoint('best_model.h5', monitor=, mode=, verbose=1, save_best_only=True)","metadata":{"_uuid":"0b809a19-5bcc-4b5f-8db1-b47236d36c66","_cell_guid":"8eb33860-0f06-4fd6-927a-f0873c9a3231","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Task 13** \n\nTrain the VGG16 for 10 epochs. In this case, VGG16 is known to work better with SGD as optimizer. We'll use a learning rate of 1e-4 and a momentum of 0.9. Plot the new validation/train curves.","metadata":{"_uuid":"dde9b317-2a6a-46a8-b6c9-10e7338e04e4","_cell_guid":"ad9f6a99-bbc9-4730-8642-5ee241d7dc92","trusted":true}},{"cell_type":"code","source":"# Use compile with the right loss, optimizer and metrics\nmodel_imgnet.compile(loss=, # Type your solution here\n              optimizer=, # Type your solution here\n              metrics=) # Type your solution here\n\n# Training\nhistory_imgnet = model_imgnet.fit(\n    x=, # Type your solution here (use the training generator without augmentation),\n    epochs=, # Type your solution here\n    validation_data=, # Type your solution here (use validation generator)\n    validation_steps=, # Type your solution here\n    steps_per_epoch=, # Type your solution here\n    callbacks=) # Type your solution here","metadata":{"_uuid":"6e585809-7196-471e-a717-f8823a94d5af","_cell_guid":"df61ef47-2348-4652-95d9-1820c48c909c","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the accuracy curves\nf,ax=plt.subplots(1,2,figsize=(18,8))\n\nax[0].plot() # Type your solution\nax[0].plot() # Type your solution\nax[0].set_title('model accuracy')\nax[0].set_ylabel('accuracy')\nax[0].set_xlabel('epoch')\nax[0].legend(['train', 'val'], loc='upper left')\n\nax[1].plot() # Type your solution\nax[1].plot() # Type your solution\nax[1].set_title('model loss')\nax[1].set_ylabel('loss')\nax[1].set_xlabel('epoch')\nax[1].legend(['train', 'val'], loc='upper left')","metadata":{"_uuid":"90a7e69a-303b-40d4-a894-9b183eab9c2b","_cell_guid":"b98a3d2e-6677-489f-af5a-ccecdb9be9d4","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Task 14**\n\nWe see that we can benefit a lot of pretrained models. With just a few epochs, we have been able to outperform previous models with a basic CNN architecture. For the next tasks, we will load the weights of the best epoch in terms of performance of our trained VGG16 in order to evaluate the model. We will use the test set for this purpose. Apply a threshold of 0.5 to obtain the class predictions and obtain the confusion matrix.","metadata":{"_uuid":"c3008fde-5060-4ef0-9cdf-082ca2806d0f","_cell_guid":"a77e09bf-416e-4fae-a111-847930588150","trusted":true}},{"cell_type":"code","source":"import itertools\n\ndef plot_confusion_matrix(cm: np.array, \n                          classes: list, \n                          title: str = 'Confusion matrix', \n                          cmap: object = plt.cm.YlGn):\n    \"\"\"\n    This function prints and plots the confusion matrix (cm). Normalization \n    can be applied by setting 'normalize=True'.\n    \n    Parameters: \n    ----------\n    cm : np.array\n        Confusion matrix.\n    classes : list\n        Data labels.\n    normalize : bool, optional\n        Apply or not normalization. The default is False.\n    title : str, optional\n        Title of the image. The default is 'Confusion matrix'.\n    cmap : object, optional\n        Color map. The default is 'plt.cm.YlGn'.\n        \n    Returns\n    -------\n    None\n    \n    \"\"\"       \n    \n    plt.figure(figsize=(8, 8), dpi=144, facecolor='w', edgecolor='k')       \n    \n    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n    \n    thresh = cm_norm.max() / 2.\n    \n    plt.imshow(cm_norm, interpolation='nearest', cmap=cmap, vmin=0, vmax=1)\n    plt.title(title, fontsize=7)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, fontsize=7, wrap=True)\n    plt.yticks(tick_marks, classes, fontsize=7, wrap=True)\n  \n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        cm = cm.astype('int')\n        plt.text(j, i, ((\"%.2f (%d)\" % (cm_norm[i, j], cm[i, j]))),\n                     horizontalalignment=\"center\", fontsize=7,\n                     color=\"white\" if cm_norm[i, j] > thresh else \"black\")\n    \n    plt.ylabel('True Label', fontsize=7)\n    plt.xlabel('Predicted Label', fontsize=7)\n    plt.tight_layout()","metadata":{"_uuid":"168d5e4b-d51b-4890-9a61-42b8fab4221c","_cell_guid":"d620866e-512c-4cd1-afb7-d7e87ca967ca","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\n# Load the model\nsaved_model =  # Type your solution here\n\n# Define test generator\ntest_gen = ImageDataGenerator(rescale=,) # Type your solution here\ntest_generator = test_gen.flow_from_dataframe(\n    dataframe=, # Type your solution here\n    x_col=, # Type your solution here\n    y_col=None,\n    class_mode=None,\n    batch_size= 64,\n    target_size=(224, 224),\n    shuffle=False\n)","metadata":{"_uuid":"8fdadb64-b397-4c01-b689-d3ede94e9910","_cell_guid":"cbaba329-a2f6-4e04-980b-4f7f99517f5d","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use the test set\npredictions = saved_model.predict() # Type your solution here\nY_test = test_df['labels']\n\n# Define threshold\nthreshold = # Type your solution here\n\n# Threshold the predictions and apply argmax to get the class (axis=1)\nclass_pred = # Type your solution here\n\n# Convert class_pred to categoricals with our encoder and inverse_transform()\nclass_pred_list = \n\n# Create confusion matrix\nconf_mat = confusion_matrix(, , labels=df['labels'].unique()) # Type your solution here\n\n# Obtain accuracy with argmax\nacc_test = accuracy_score(, ) # Type your solution\n\nprint(\"Accuracy test:\", acc_test)\n\nplot_confusion_matrix(cm=conf_mat, classes=df['labels'].unique(),\n                      title='Confusion matrix', cmap='Blues')","metadata":{"_uuid":"b9fca62e-d5f9-43e0-b4df-40417d22bda4","_cell_guid":"29930496-55a5-4769-a1dc-f808a8d68870","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Task 15**\n\nObtain a sklearn report (F1, precision and recall) of the test set.\n\n**Q3**: What all these parameters stand for? Precision, Recall, F1-Score, Accuracy, Macro Average and Weighted Average.","metadata":{"_uuid":"c6d695c0-2a71-408b-8a87-3d0542908fb5","_cell_guid":"8da0b3d6-6e8d-4bb2-8be9-b4e79b5e6c06","trusted":true}},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# Generate a classification report\nreport = classification_report(, , target_names=df['labels'].unique()) # Type your solution here\n\nprint(report)","metadata":{"_uuid":"111f698b-d323-4852-9afa-499720828638","_cell_guid":"13674e60-bfdc-431b-a832-febf50727b16","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Task 16**\n\nLet's show some exmaples of the predictions!\n\nNot too bad, isn't it?","metadata":{"_uuid":"694ee246-3487-4e53-a6b1-0b2301c56edf","_cell_guid":"caabfbc3-abf8-4aea-9179-bb0ab5c7c9f2","trusted":true}},{"cell_type":"code","source":"# Add the predicted labels to our test dataset\ntest_df['predicted_labels'] =  # Type your solution here\n\n# Extract 9 random samples from test set\nsample_test = # Type your solution here\n\n# Plot the images with their predicted label\nplt.figure(figsize=(12, 12))\nfor index, row in sample_test.iterrows():\n    filename = row['filename']\n    category = row['predicted_labels']\n    img = load_img(filename, target_size=(256, 256))\n    plt.subplot(3, 3, index+1)\n    plt.imshow(img)\n    plt.xlabel(category)\nplt.tight_layout()\nplt.show()","metadata":{"_uuid":"efa0114f-df40-455e-b959-5afd6c318a1c","_cell_guid":"5ae841a2-a52e-42f9-9f96-127b72ff6021","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### QUESTIONS\n\n**Q1** (Task 2):\n\n**Q2** (Task 7):\n\n**Q3** (Task 14):","metadata":{"_uuid":"ca301596-724d-4007-b8c0-5b924670d50a","_cell_guid":"b9ba4c3e-177e-415d-a94b-a4c2f162f84c","trusted":true}},{"cell_type":"code","source":"","metadata":{"_uuid":"4a2050d9-2ea8-4b49-88e3-2c8e1125f9e5","_cell_guid":"99ad21f9-3c90-4d68-8466-40d2cb6b3c5b","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}