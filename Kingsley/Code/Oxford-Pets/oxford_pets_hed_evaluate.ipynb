{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"last\" # all | last | last_expr | none "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name in dir():\n",
    "#     if not name.startswith('_'):\n",
    "#         del globals()[name]\n",
    "\n",
    "# !tar -xf ./data/images.tar.gz\n",
    "# !tar -xf ./data/annotations.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation and model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============= Import required packaages ==============\n",
    "import time\n",
    "\n",
    "# Import all custom variables and modules\n",
    "from custom_classes_defs.preprocessing import *\n",
    "from custom_classes_defs.hed import *\n",
    "\n",
    "RND_STATE = 247\n",
    "BATCH_SIZE = 64\n",
    "FREEZE = 0\n",
    "EPOCHS = 200\n",
    "keras.utils.set_random_seed(RND_STATE)\n",
    "from keras.utils import plot_model\n",
    "\n",
    "INTERACTIVE_SESSION = False\n",
    "\n",
    "# -------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify tensorflow/keras versions\n",
    "print(f\"tensorflow version: {tf.__version__}\")\n",
    "print(f\"keras version: {keras.__version__}\")\n",
    "\n",
    "# Verify CPU/GPU availability\n",
    "print(tf.config.list_physical_devices())\n",
    "NUM_GPU = len(tf.config.list_physical_devices('GPU'))\n",
    "print(f\"Number of GPUs assigned for computation: {NUM_GPU}\")\n",
    "\n",
    "if NUM_GPU:\n",
    "    # print GPU info\n",
    "    !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pets = Oxford_Pets(\n",
    "        input_dir = \"./data/images/\",\n",
    "        target_dir = \"./data/annotations/trimaps/\",\n",
    "        img_size = (160, 160),\n",
    "        batch_size = BATCH_SIZE\n",
    "    )\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = \\\n",
    "        pets.split_data(train_ratio=0.5, val_ratio=0.2, seed=RND_STATE)\n",
    "\n",
    "\n",
    "print(f\"training data (size = {pets.train_size})\")\n",
    "print(f\"validation data (size = {pets.validation_size})\")\n",
    "print(f\"test data (size = {pets.test_size})\")\n",
    "print(\"Data images tensor:\",train_dataset.element_spec[0])\n",
    "print(\"Data labels tensor:\",train_dataset.element_spec[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model configurations\n",
    "conf = model_config(\n",
    "    epochs=100,\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    save_path=f'./oxford-pets/hed{FREEZE}',\n",
    "    img_shape=pets.img_size,\n",
    "    target_size=pets.img_size,\n",
    "    train_size=pets.train_size,\n",
    "    test_size=pets.test_size,\n",
    "    validation_size=pets.validation_size,\n",
    "    channels_dim=(3,3),\n",
    "    pos_label=pets.pos_label,\n",
    "    multiple_gpu_device=(NUM_GPU>1)\n",
    ")\n",
    "\n",
    "assert not(conf.new_training_session)\n",
    "\n",
    "out_no = 4\n",
    "hed_out = f'output{out_no}_'\n",
    "\n",
    "# conf.double_check(INTERACTIVE_SESSION)\n",
    "conf.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n{}\\n\\t{}\\n{}\".format('='*55,f'Build model', '-'*55))\n",
    "\n",
    "if conf.multiple_gpu_device:\n",
    "\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    print(f\"Number of devices: {strategy.num_replicas_in_sync}\")\n",
    "\n",
    "m_obj = HED2D(model_arch=conf.model_arch)\n",
    "model = m_obj.build_model()\n",
    "\n",
    "\n",
    "# model.summary()\n",
    "# keras.utils.plot_model(model, 'm_obj.png',show_shapes=True)\n",
    "# plot_model(model, 'm_obj.png',show_shapes=True)\n",
    "num_trainable_weights = sum([np.prod(w.shape) for w in model.trainable_weights])\n",
    "print(f\"Total number of parameters: {model.count_params():,}\")\n",
    "print(f\"Total trainable wieghts: {num_trainable_weights:,}\")\n",
    "print(f\"Total non-trainable wieghts: {model.count_params()-num_trainable_weights:,}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n{}\\n\\t{}\\n{}\".format('='*55,f'Train {m_obj.Name} model', '-'*55))\n",
    "\n",
    "train_history = None\n",
    "# model, train_history = \\\n",
    "#     conf.execute_training(\n",
    "#         model, \n",
    "#         data=None, \n",
    "#         plot_history=INTERACTIVE_SESSION\n",
    "# )\n",
    "\n",
    "best_model_track = sorted(glob(conf.save_path+'/*.h5'))\n",
    "if len(best_model_track):\n",
    "    model.load_weights(best_model_track[-1])\n",
    "    print(\"Best model weights loaded!\")\n",
    "else:\n",
    "    print(f\"No model weights found in {conf.save_path}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if INTERACTIVE_SESSION:\n",
    "    show_convergence(train_history.history, [hed_out+'accuracy','val_'+hed_out+'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if INTERACTIVE_SESSION:\n",
    "    show_convergence(train_history.history, [hed_out+'f1_score','val_'+hed_out+'f1_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if INTERACTIVE_SESSION:\n",
    "    show_convergence(train_history.history, 'lr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\\n\\n{}\\n\\t{}\\n{}\".format('='*55,f'Evaluate {m_obj.Name} model', '-'*55))\n",
    "y_preds = model.predict(test_dataset, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if INTERACTIVE_SESSION:\n",
    "    for out_no in range(6):\n",
    "        pets.display_sample_image(y_preds[out_no], 'test')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using scikit-learn\n",
    "for out_no in range(6):\n",
    "    scores = m_obj.evaluate_sklearn(test_dataset, y_preds[out_no],report=True, average='weighted')\n",
    "    print(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
