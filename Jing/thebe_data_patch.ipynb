{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from itertools import compress\n",
    "from skimage.util.shape import view_as_windows\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np  \n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate files into one big file first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_and_save(folder_path, output_directory, output_file):\n",
    "    files = os.listdir(folder_path)\n",
    "    print(files)\n",
    "\n",
    "    np_files = [f for f in files if f.endswith('.npy')]\n",
    "    arrays = [np.load(os.path.join(folder_path, f)) for f in np_files]\n",
    "    concatenated_array = np.concatenate(arrays, axis=0)\n",
    "    \n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "    \n",
    "    output_path = os.path.join(output_directory, output_file)\n",
    "    print(\"Stacked array shape:\", concatenated_array.shape)\n",
    "    \n",
    "    np.save(output_path, concatenated_array)\n",
    "    print(\"Concatenation complete. Array saved as\", output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['seistrain1.npy', 'seistrain2.npy', 'seistrain3.npy', 'seistrain4.npy', 'seistrain5.npy', 'seistrain6.npy', 'seistrain7.npy', 'seistrain8.npy', 'seistrain9.npy']\n",
      "Stacked array shape: (900, 3174, 1537)\n",
      "Concatenation complete. Array saved as data_download/seis_train\\seistrain_full.npy\n"
     ]
    }
   ],
   "source": [
    "path = \"data_download/seis_train\"\n",
    "output_file = \"seistrain_full.npy\"\n",
    "concatenate_and_save(path, path, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['seisval1.npy', 'seisval2.npy']\n",
      "Stacked array shape: (200, 3174, 1537)\n",
      "Concatenation complete. Array saved as data_download/seis_val\\seisval_full.npy\n"
     ]
    }
   ],
   "source": [
    "path = \"data_download/seis_val\"\n",
    "output_file = \"seisval_full.npy\"\n",
    "concatenate_and_save(path, path, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['seistest1.npy', 'seistest2.npy', 'seistest3.npy', 'seistest4.npy', 'seistest5.npy', 'seistest6.npy', 'seistest7.npy']\n",
      "Stacked array shape: (703, 3174, 1537)\n",
      "Concatenation complete. Array saved as data_download/seis_test\\seistest_full.npy\n"
     ]
    }
   ],
   "source": [
    "path = \"data_download/seis_test\"\n",
    "output_file = \"seistest_full.npy\"\n",
    "concatenate_and_save(path, path, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the training dataset, apply normalization and prepare patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 32.7GB memory is needed for seistrain dataset normalization. thus it is applied before the stacking of individual seistrain file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_norm(input_path, output_folder):\n",
    "    seismicfiles = os.listdir(input_path)\n",
    "    print(seismicfiles)\n",
    "    \n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for file_name in seismicfiles:\n",
    "        print(file_name)\n",
    "        path = os.path.join(input_path+file_name)\n",
    "        seismic = np.load(path)\n",
    "        seismic = np.moveaxis(seismic,-2,-1)         # re-sort in the order of # IL, Z, XL  \n",
    "        seismic = (seismic-seismic.min(axis=(1,2), keepdims=True))/(seismic.max(axis=(1,2), keepdims=True)-seismic.min(axis=(1,2), keepdims=True))\n",
    "        output_path = os.path.join(output_folder, file_name[:-4] + '_norm.npy')\n",
    "        np.save(output_path, seismic)\n",
    "        print(\"Process complete. Array saved as\", output_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['seistrain1.npy', 'seistrain2.npy', 'seistrain3.npy', 'seistrain4.npy', 'seistrain5.npy', 'seistrain6.npy', 'seistrain7.npy', 'seistrain8.npy', 'seistrain9.npy']\n",
      "seistrain1.npy\n",
      "Process complete. Array saved as data_download/full_data/norm\\seistrain1_norm.npy\n",
      "seistrain2.npy\n",
      "Process complete. Array saved as data_download/full_data/norm\\seistrain2_norm.npy\n",
      "seistrain3.npy\n",
      "Process complete. Array saved as data_download/full_data/norm\\seistrain3_norm.npy\n",
      "seistrain4.npy\n",
      "Process complete. Array saved as data_download/full_data/norm\\seistrain4_norm.npy\n",
      "seistrain5.npy\n",
      "Process complete. Array saved as data_download/full_data/norm\\seistrain5_norm.npy\n",
      "seistrain6.npy\n",
      "Process complete. Array saved as data_download/full_data/norm\\seistrain6_norm.npy\n",
      "seistrain7.npy\n",
      "Process complete. Array saved as data_download/full_data/norm\\seistrain7_norm.npy\n",
      "seistrain8.npy\n",
      "Process complete. Array saved as data_download/full_data/norm\\seistrain8_norm.npy\n",
      "seistrain9.npy\n",
      "Process complete. Array saved as data_download/full_data/norm\\seistrain9_norm.npy\n"
     ]
    }
   ],
   "source": [
    "path = \"data_download/seis_train/\"\n",
    "output_path = \"data_download/full_data/norm\"\n",
    "prepare_norm(path,output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['seistrain1_norm.npy', 'seistrain2_norm.npy', 'seistrain3_norm.npy', 'seistrain4_norm.npy', 'seistrain5_norm.npy', 'seistrain6_norm.npy', 'seistrain7_norm.npy', 'seistrain8_norm.npy', 'seistrain9_norm.npy']\n",
      "Stacked array shape: (900, 1537, 3174)\n",
      "Concatenation complete. Array saved as data_download/full_data/seistrain_norm_full.npy\n"
     ]
    }
   ],
   "source": [
    "path = \"data_download/full_data/norm/\"\n",
    "output_path = \"data_download/full_data/\"\n",
    "output_file = \"seistrain_norm_full.npy\"\n",
    "concatenate_and_save(path, output_path, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data_download/full_data/\"\n",
    "seistrain = np.load(os.path.join(path,\"seistrain_norm_full.npy\"))\n",
    "faulttrain = np.load(os.path.join(path,\"faulttrain_full.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "faulttrain= np.moveaxis(faulttrain,-2,-1) # IL, Z, XL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seismic train shape (900, 1537, 3174)\n",
      "Fault train shape (900, 1537, 3174)\n"
     ]
    }
   ],
   "source": [
    "print('Seismic train shape',seistrain.shape)\n",
    "print('Fault train shape',faulttrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0 True False\n"
     ]
    }
   ],
   "source": [
    "print(seistrain.max(),seistrain.min(), faulttrain.max(), faulttrain.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setup for the splitting patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276\n"
     ]
    }
   ],
   "source": [
    "IL, Z, XL = faulttrain.shape\n",
    "\n",
    "im_height = Z\n",
    "im_width = XL\n",
    "splitsize = 96\n",
    "stepsize = 48\n",
    "overlapsize = splitsize-stepsize\n",
    "pixelThre = int(0.03*splitsize*splitsize)\n",
    "print(pixelThre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horizontal_splits_number 66\n",
      "width_after_pad 3216\n",
      "left_pad,right_pad 21 21\n",
      "vertical_splits_number 32\n",
      "height_after_pad 1584\n",
      "top_pad,bottom_pad 23 24\n"
     ]
    }
   ],
   "source": [
    "horizontal_splits_number = int(np.ceil((im_width-overlapsize)/stepsize))\n",
    "print(\"horizontal_splits_number\", horizontal_splits_number)\n",
    "width_after_pad = stepsize*horizontal_splits_number+overlapsize\n",
    "print(\"width_after_pad\", width_after_pad)\n",
    "left_pad = int((width_after_pad-im_width)/2)\n",
    "right_pad = width_after_pad-im_width-left_pad\n",
    "print(\"left_pad,right_pad\",left_pad,right_pad)\n",
    "\n",
    "vertical_splits_number = int(np.ceil((im_height-overlapsize)/stepsize))\n",
    "print(\"vertical_splits_number\",vertical_splits_number)\n",
    "height_after_pad = stepsize*vertical_splits_number+overlapsize\n",
    "print(\"height_after_pad\",height_after_pad)\n",
    "top_pad = int((height_after_pad-im_height)/2)\n",
    "bottom_pad = height_after_pad-im_height-top_pad\n",
    "print(\"top_pad,bottom_pad\", top_pad,bottom_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_Image(bigImage,isMask,top_pad,bottom_pad,left_pad,right_pad,splitsize,stepsize,vertical_splits_number,horizontal_splits_number):\n",
    "#     print(bigImage.shape)\n",
    "    if isMask==True:\n",
    "        arr = np.pad(bigImage,((top_pad,bottom_pad),(left_pad,right_pad)),\"reflect\")\n",
    "        splits = view_as_windows(arr, (splitsize,splitsize),step=stepsize)\n",
    "        splits = splits.reshape((vertical_splits_number*horizontal_splits_number,splitsize,splitsize))\n",
    "    else: \n",
    "        arr = np.pad(bigImage,((top_pad,bottom_pad),(left_pad,right_pad),(0,0)),\"reflect\")\n",
    "        splits = view_as_windows(arr, (splitsize,splitsize,3),step=stepsize)\n",
    "        splits = splits.reshape((vertical_splits_number*horizontal_splits_number,splitsize,splitsize,3))\n",
    "    return splits # return list of arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181029\n",
      "181029\n",
      "(96, 96)\n",
      "read images in 318.36458945274353 sec\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "X = []\n",
    "Y = []\n",
    "for i in range(0,900,1):\n",
    "    mask = faulttrain[i]\n",
    "    splits = split_Image(mask, True,top_pad,bottom_pad,left_pad,right_pad,splitsize,stepsize,vertical_splits_number,horizontal_splits_number)\n",
    "#     print(splits.shape)\n",
    "    t = (splits.sum((1,2)) < pixelThre)\n",
    "    no_label_element_index = list(compress(range(len(t)), t))\n",
    "    # get all the indexes of the no label pieces by adding elements in axis 2 and 3.\n",
    "    splits = np.delete(splits, no_label_element_index,0) # delete element i along axis 0\n",
    "#     print(\"splits.shape\", splits.shape)\n",
    "    Y.extend(splits)\n",
    "    \n",
    "    img = seistrain[i]\n",
    "    splits = split_Image(img, True,top_pad,bottom_pad,left_pad,right_pad,splitsize,stepsize,vertical_splits_number,horizontal_splits_number)\n",
    "    splits = np.delete(splits, no_label_element_index,0) # delete element i along axis 0\n",
    "#     print(\"splits.shape\", splits.shape)\n",
    "    X.extend(splits)\n",
    "#     break\n",
    "\n",
    "print(len(Y))\n",
    "print(len(X))\n",
    "print(X[0].shape)\n",
    "print(\"read images in {} sec\".format(time.time()-t_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "bool\n",
      "float32\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "print(X[0].dtype)\n",
    "print(Y[0].dtype)\n",
    "X = np.asarray(X, dtype=np.float32)\n",
    "Y = np.asarray(Y, dtype=np.float32)\n",
    "print(X[0].dtype)\n",
    "print(Y[0].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"data_download/full_data/patches/seismic/train\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "directory = \"data_download/full_data/patches/fault/train\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches_path = 'data_download/full_data/patches'\n",
    "\n",
    "for i in range(len(X)):\n",
    "    np.save(\"{}/seismic/train/{}.npy\".format(patches_path, i),X[i])\n",
    "    np.save(\"{}/fault/train/{}.npy\".format(patches_path, i),Y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the validation dataset, apply normalization and prepare patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data_download/full_data/\"\n",
    "seisval = np.load(os.path.join(path,\"seisval_full.npy\"))\n",
    "faultval = np.load(os.path.join(path,\"faultval_full.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seisval= np.moveaxis(seisval,-2,-1) \n",
    "faultval= np.moveaxis(faultval,-2,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seismic validation shape (200, 1537, 3174)\n",
      "Fault validation shape (200, 1537, 3174)\n"
     ]
    }
   ],
   "source": [
    "print('Seismic validation shape',seisval.shape)\n",
    "print('Fault validation shape',faultval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seisval = (seisval-seisval.min(axis=(1,2), keepdims=True))/(seisval.max(axis=(1,2), keepdims=True)-seisval.min(axis=(1,2), keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0 True False\n"
     ]
    }
   ],
   "source": [
    "print(seisval.max(),seisval.min(), faultval.max(), faultval.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64317\n",
      "64317\n",
      "(96, 96)\n",
      "read images in 101.6322500705719 sec\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "X = []\n",
    "Y = []\n",
    "for i in range(0,200,1):\n",
    "    mask = faultval[i]\n",
    "    splits = split_Image(mask, True,top_pad,bottom_pad,left_pad,right_pad,splitsize,stepsize,vertical_splits_number,horizontal_splits_number)\n",
    "#     print(splits.shape)\n",
    "    t = (splits.sum((1,2)) < pixelThre)\n",
    "    no_label_element_index = list(compress(range(len(t)), t))\n",
    "    # get all the indexes of the no label pieces by adding elements in axis 2 and 3.\n",
    "    splits = np.delete(splits, no_label_element_index,0) # delete element i along axis 0\n",
    "#     print(\"splits.shape\", splits.shape)\n",
    "    Y.extend(splits)\n",
    "    \n",
    "    img = seisval[i]\n",
    "    splits = split_Image(img, True,top_pad,bottom_pad,left_pad,right_pad,splitsize,stepsize,vertical_splits_number,horizontal_splits_number)\n",
    "    splits = np.delete(splits, no_label_element_index,0) # delete element i along axis 0\n",
    "    X.extend(splits)\n",
    "\n",
    "print(len(Y))\n",
    "print(len(X))\n",
    "print(X[0].shape)\n",
    "print(\"read images in {} sec\".format(time.time()-t_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(X, dtype=np.float32)\n",
    "Y = np.asarray(Y, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"data_download/full_data/patches/seismic/val\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "directory = \"data_download/full_data/patches/fault/val\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches_path = 'data_download/full_data/patches'\n",
    "\n",
    "for i in range(len(X)):\n",
    "    np.save(\"{}/seismic/val/{}.npy\".format(patches_path, i),X[i])\n",
    "    np.save(\"{}/fault/val/{}.npy\".format(patches_path, i),Y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the same procedure for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['seistest1.npy', 'seistest2.npy', 'seistest3.npy', 'seistest4.npy', 'seistest5.npy', 'seistest6.npy', 'seistest7.npy']\n",
      "seistest1.npy\n",
      "Process complete. Array saved as data_download/full_data/seistest_norm\\seistest1_norm.npy\n",
      "seistest2.npy\n",
      "Process complete. Array saved as data_download/full_data/seistest_norm\\seistest2_norm.npy\n",
      "seistest3.npy\n",
      "Process complete. Array saved as data_download/full_data/seistest_norm\\seistest3_norm.npy\n",
      "seistest4.npy\n",
      "Process complete. Array saved as data_download/full_data/seistest_norm\\seistest4_norm.npy\n",
      "seistest5.npy\n",
      "Process complete. Array saved as data_download/full_data/seistest_norm\\seistest5_norm.npy\n",
      "seistest6.npy\n",
      "Process complete. Array saved as data_download/full_data/seistest_norm\\seistest6_norm.npy\n",
      "seistest7.npy\n",
      "Process complete. Array saved as data_download/full_data/seistest_norm\\seistest7_norm.npy\n"
     ]
    }
   ],
   "source": [
    "path = \"data_download/seis_test/\"\n",
    "output_path = \"data_download/full_data/seistest_norm\"\n",
    "prepare_norm(path,output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['seistest1_norm.npy', 'seistest2_norm.npy', 'seistest3_norm.npy', 'seistest4_norm.npy', 'seistest5_norm.npy', 'seistest6_norm.npy', 'seistest7_norm.npy']\n",
      "Stacked array shape: (703, 1537, 3174)\n",
      "Concatenation complete. Array saved as data_download/full_data/seistest_norm_full.npy\n"
     ]
    }
   ],
   "source": [
    "path = \"data_download/full_data/seistest_norm/\"\n",
    "output_path = \"data_download/full_data/\"\n",
    "output_file = \"seistest_norm_full.npy\"\n",
    "concatenate_and_save(path, output_path, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data_download/full_data/\"\n",
    "seistest = np.load(os.path.join(path,\"seistest_norm_full.npy\"))\n",
    "faulttest = np.load(os.path.join(path,\"faulttest_full.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "faulttest= np.moveaxis(faulttest,-2,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seismic test shape (703, 1537, 3174)\n",
      "Fault test shape (703, 1537, 3174)\n"
     ]
    }
   ],
   "source": [
    "print('Seismic test shape',seistest.shape)\n",
    "print('Fault test shape',faulttest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0 True False\n"
     ]
    }
   ],
   "source": [
    "print(seistest.max(),seistest.min(), faulttest.max(), faulttest.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66077\n",
      "66077\n",
      "(96, 96)\n",
      "read images in 101.14579248428345 sec\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "X = []\n",
    "Y = []\n",
    "for i in range(0,200,1):\n",
    "    mask = faulttest[i]\n",
    "    splits = split_Image(mask, True,top_pad,bottom_pad,left_pad,right_pad,splitsize,stepsize,vertical_splits_number,horizontal_splits_number)\n",
    "#     print(splits.shape)\n",
    "    t = (splits.sum((1,2)) < pixelThre)\n",
    "    no_label_element_index = list(compress(range(len(t)), t))\n",
    "    # get all the indexes of the no label pieces by adding elements in axis 2 and 3.\n",
    "    splits = np.delete(splits, no_label_element_index,0) # delete element i along axis 0\n",
    "#     print(\"splits.shape\", splits.shape)\n",
    "    Y.extend(splits)\n",
    "    \n",
    "    img = seistest[i]\n",
    "    splits = split_Image(img, True,top_pad,bottom_pad,left_pad,right_pad,splitsize,stepsize,vertical_splits_number,horizontal_splits_number)\n",
    "    splits = np.delete(splits, no_label_element_index,0) # delete element i along axis 0\n",
    "    X.extend(splits)\n",
    "\n",
    "print(len(Y))\n",
    "print(len(X))\n",
    "print(X[0].shape)\n",
    "print(\"read images in {} sec\".format(time.time()-t_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(X, dtype=np.float32)\n",
    "Y = np.asarray(Y, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"data_download/full_data/patches/seismic/test\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "directory = \"data_download/full_data/patches/fault/test\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches_path = 'data_download/full_data/patches'\n",
    "\n",
    "for i in range(len(X)):\n",
    "    np.save(\"{}/seismic/test/{}.npy\".format(patches_path, i),X[i])\n",
    "    np.save(\"{}/fault/test/{}.npy\".format(patches_path, i),Y[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
